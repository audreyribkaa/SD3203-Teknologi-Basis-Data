---
title: "Tugas laporan TBD"
output: github_document
author: "Audrey Ribka Desmonda Manihuruk"
---

# TUGAS TBD - Three Ways of Storing and Accessing Lots of Images in Python
# Tiga Metode Penyimpanan dan Akses Gambar dalam Jumlah Besar di Python

## Pendahuluan
### Menyimpan dan Mengakses Banyak Gambar di Python dengan Tiga Metode
### Pengaturan Dataset
Langkah pertama adalah mengimpor library yang diperlukan, termasuk numpy untuk manipulasi array, pickle untuk membaca data serial,
dan Path dari pathlib untuk mengelola path file. Path menuju dataset CIFAR-10 disimpan dalam variabel data_dir. Kemudian, sebuah
fungsi bernama unpickle dibuat untuk membaca file pickle CIFAR-10. Selanjutnya, setiap file batch dalam direktori data diiterasi.
Setiap file batch dibuka menggunakan fungsi unpickle, dan setiap gambar dalam batch diambil sebagai array 1D yang diratakan.
Array tersebut kemudian dipecah menjadi tiga saluran untuk merekonstruksi gambar RGB yang asli, dan semua gambar tersebut disusun 
kembali menjadi array 3D menggunakan np.dstack. Di sini kita akan memahami perbedaan antara menyimpan gambar langsung ke disk, 
menggunakan LMDB, dan menggunakan HDF5. Hal ini bertujuan agar kita dapat membuat keputusan yang tepat dalam memilih metode 
penyimpanan yang optimal untuk analisis gambar medis berukuran terabyte. Terutama, kita akan mempertimbangkan kinerja, efisiensi 
penyimpanan, dan kompleksitas implementasi dari masing-masing metode.

## A Dataset to Play With
Dataset ini terdiri dari 60.000 gambar berwarna berukuran 32x32 piksel yang terbagi ke dalam berbagai kelas objek, seperti anjing, 
kucing, dan pesawat. Walaupun CIFAR-10 tidak terlalu besar, jika kita menggunakan dataset yang lebih besar seperti TinyImages, 
kita akan membutuhkan sekitar 400GB ruang penyimpanan di disk, yang kemungkinan besar akan menjadi kendala. Teks ini ingin 
menekankan perbedaan dalam kebutuhan ruang penyimpanan antara dataset kecil seperti CIFAR-10 dan dataset yang jauh lebih besar.

### 1. Penyimpanan Gambar dalam Format File Disk
```python
pip install Pillow
conda install -c conda-forge pillow
```
Penyimpanan gambar dalam format file disk adalah pendekatan yang umum dan simpel yang sering digunakan. Prosesnya melibatkan 
pembuatan direktori khusus untuk menyimpan gambar, di mana setiap gambar disimpan sebagai file PNG langsung di dalamnya. Meskipun 
pendekatan ini mudah dipahami dan tidak memerlukan pustaka tambahan, namun memiliki kelemahan dalam hal penggunaan ruang disk yang 
besar. Setiap gambar disimpan sebagai file terpisah, sehingga dapat menjadi kurang efisien untuk gambar berskala besar atau pengolahan 
gambar yang melibatkan banyak gambar sekaligus.

### 2. Penyimpanan gambar dengan LMDB
```python
pip install lmdb
conda install -c conda-forge python-lmdb
```

LMDB (Lightning Memory-Mapped Database) adalah sistem basis data yang sangat cepat dan efisien untuk menyimpan dan mengakses data 
dalam jumlah besar. Untuk menggunakan LMDB, pertama-tama kita perlu menginstal pustaka Python yang diperlukan, seperti lmdb.
Langkah pertama adalah membuat direktori baru untuk basis data LMDB. Kemudian, kita membuat lingkungan LMDB dan menambahkan
gambar-gambar ke dalam basis data ini. Gambar-gambar tersebut perlu dikonversi ke format biner sebelum disimpan. Keuntungan utama
menggunakan LMDB adalah kinerja tinggi dan efisiensi penyimpanan, karena LMDB dapat mengelola data dalam jumlah besar dengan cepat. 
Namun, kompleksitas implementasi dan kebutuhan untuk konversi format data dapat menjadi kekurangan.

### 3. Penyimpanan Gambar dengan HDF5
```pyhon
pip install h5py
conda install -c conda-forge h5py
```

HDF5 (Hierarchical Data Format version 5) adalah format file dan kumpulan alat yang mendukung penyimpanan dan pengelolaan data yang 
sangat besar dan kompleks. Untuk menyimpan gambar menggunakan HDF5, kita akan membuat file HDF5 dan menambahkan setiap gambar sebagai 
dataset dalam file tersebut.
Saat menggunakan format HDF5 untuk menyimpan gambar, hal pertama yaitu pembuatan file HDF5 yang berfungsi sebagai tempat penyimpanan gambar. 
Dalam format ini, gambar-gambar itu sendiri ditempatkan di dalam dataset HDF5. Kelebihan dari metode ini adalah kombinasi baik antara 
kinerjanya yang sesuai  dan kesederhanaan penggunaan, ditambah dengan kemampuan untuk menangani struktur dataset yang lebih kompleks. 
Kompleks yang dimagsud seperti menangani dataset yang terdiri dari beberapa gambar, gambar dengan dimensi yang berbeda, atau bahkan data 
lain yang terkait dengan gambar seperti label atau metadata. Kelebihan ini memungkinkan kita untuk membuat struktur dataset yang sesuai 
dengan kebutuhan aplikasi. Namun, metode ini juga memiliki kekurangan yaitu memerlukan penyesuaian saat menemukan data dalam skala besar 
dengan jumlah gambar yang banyak.

## Storing a Single Image
Melakukan perbandingan kuantitatif terhadap waktu yang dibutuhkan untuk membaca dan menulis file, serta seberapa banyak memori disk yang 
akan digunakan, dengan fokus pada penyimpanan gambar tunggal. Eksperimen ini akan dilakukan dengan berbagai jumlah file, mulai dari satu 
gambar hingga 100.000 gambar. Langkah pertama dalam persiapan eksperimen adalah membuat folder terpisah untuk setiap metode penyimpanan, 
yang akan menyimpan semua file atau gambar yang diperlukan. 

```python
from pathlib import Path
disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")
disk_dir.mkdir(parents=True, exist_ok=True)
lmdb_dir.mkdir(parents=True, exist_ok=True)
hdf5_dir.mkdir(parents=True, exist_ok=True)
```
### Storing to Disk

```python
from PIL import Image
import csv

def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")

    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label])
```
Metode ini memungkinkan untuk memanipulasi label tanpa harus memuat gambar. Dalam eksperimen yang disebutkan, 
label disimpan dalam file .csv terpisah, sehingga memungkinkan untuk mengelola dan mengubah label secara terpisah dari gambar.

### Storing to LMDB
```python
class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary
        # for this dataset, but some datasets may include images of
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]
        self.image = image.tobytes()
        self.label = label
    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)
```
LMDB adalah sistem penyimpanan key-value di mana setiap entri disimpan sebagai array byte. Dalam konteks ini, kunci akan menjadi 
pengenal unik untuk setiap gambar, dan nilai akan menjadi gambar itu sendiri. Baik kunci maupun nilai diharapkan berupa string, 
sehingga penggunaan umum adalah menyerialisasi nilai sebagai string, dan kemudian men-deserialize-nya saat membacanya kembali.

```python
import lmdb
import pickle
def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = image.nbytes * 10
    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)
    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()
```


### Storing With HDF5
```python
import h5py
def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")
    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close()
```
Fungsi `store_single_hdf5` didesain untuk menyimpan gambar CIFAR ke dalam format file HDF5. Dengan menerima tiga parameter: 
`image`, `image_id`, dan `label`, fungsi ini memulai prosesnya dengan membuat sebuah file HDF5 baru menggunakan `h5py.File`, 
di mana nama file menggunakan ID gambar sebagai identifikasi. Selanjutnya, array gambar disimpan dalam dataset bernama "image", 
yang menggunakan tipe data unsigned integer 8-bit. Selain itu, dataset meta dibuat untuk menyimpan label gambar. Setelah dataset 
terbentuk, file HDF5 ditutup dengan menggunakan `file.close()`.

### Eksperimen Storing Single Images
```python
_store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
)
```

```python
from timeit import timeit
store_single_timings = dict()
for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```
Dalam `_store_single_funcs`, fungsi-fungsi yang berkaitan dengan penyimpanan gambar dalam berbagai format disusun. Pengukuran waktu eksekusi 
dilakukan untuk setiap metode penyimpanan menggunakan fungsi `timeit`, dan hasilnya direkam dalam kamus `store_single_timings`. Hasil 
pengukuran waktu kemudian dicetak untuk setiap metode. Meskipun LMDB menawarkan keunggulan dalam kinerja, disarankan untuk menggunakan 
penyimpanan disk karena format yang lebih mudah dibaca manusia dan dapat diakses langsung dari browser sistem file.

## Storing Many Images
### Adjusting the Code for Many Images
```python
store_many_disk(images, labels):
    """ Stores an array of images to disk
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Save all the images one by one
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")

    # Save all the labels to the csv file
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # This typically would be more than just one value per row
            writer.writerow([label])

def store_many_lmdb(images, labels):
    """ Stores an array of images to LMDB.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    map_size = num_images * images[0].nbytes * 10

    # Create a new LMDB DB for all the images
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)

    # Same as before — but let's write all the images in a single transaction
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # All key-value pairs need to be Strings
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

def store_many_hdf5(images, labels):
    """ Stores an array of images to HDF5.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close()
```

### Preparing the Dataset
```python
cutoffs = [10, 100, 1000, 10000, 100000]
# Let's double our images so that we have 100,000
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)
# Make sure you actually have 100,000 images and labels
print(np.shape(images))
print(np.shape(labels))
```
::: {.output .stream .stdout}
    (100000, 32, 32, 3)
    (100000,)
:::

### Eksperimen Storing Many Images
```python
_store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)
from timeit import timeit
store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}
for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)
        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}")
```
Pada setiap iterasi, kita menggunakan timeit untuk mengukur waktu eksekusi dari pemanggilan fungsi penyimpanan dengan data yang dipotong 
sesuai dengan cutoff. Hasil waktu eksekusi kemudian disimpan di dalam store_many_timings sesuai dengan metode penyimpanan yang sedang dievaluasi.
Setelah itu, hasil waktu eksekusi untuk setiap metode penyimpanan dicetak. Ini memberikan informasi tentang waktu yang dibutuhkan untuk 
menyimpan data menggunakan setiap metode pada setiap titik potong (cutoff).

## Reading a Single Image
### Reading From Disk

```python
def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image
        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))
    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])
    return image, label
```
Membaca sebuah gambar dan label terkait dari disk. 
Fungsi ini kemungkinan besar merupakan bagian dari sebuah sistem yang menyimpan data gambar dan label ke dalam disk, dan kemudian 
membacanya kembali dari disk.

### Reading From LMDB
```python
def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image
        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)
    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()
    return image, label
```

### Reading From HDF5
```python
def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image
        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")
    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))
    return image, label
```
Secara inti, fungsi-fungsi tersebut bertanggung jawab untuk membaca gambar dari tiga jenis penyimpanan yang berbeda:

1. **`read_single_disk(image_path)`**: Fungsi ini membaca gambar dari penyimpanan disk. Parameter `image_path` adalah alamat file dari gambar yang ingin dibaca. Fungsi ini mengakses file gambar di disk dan mengembalikan gambar tersebut dalam bentuk yang sesuai.

2. **`read_single_lmdb(image_key)`**: Fungsi ini membaca gambar dari penyimpanan LMDB (Lightning Memory-Mapped Database). Parameter `image_key` mungkin adalah kunci atau identifier untuk gambar yang ingin dibaca. Fungsi ini mengakses LMDB dan mengembalikan gambar yang terkait dengan kunci tersebut.

3. **`read_single_hdf5(image_key)`**: Fungsi ini membaca gambar dari penyimpanan HDF5. Parameter `image_key` mungkin adalah kunci atau path ke gambar yang ingin dibaca dalam struktur HDF5. Fungsi ini mengakses dataset HDF5 dan mengembalikan gambar yang terkait.

Jadi, secara inti, fungsi-fungsi ini memfasilitasi akses dan pembacaan gambar dari berbagai jenis penyimpanan yang berbeda, yaitu disk, LMDB, dan HDF5.

```python
_read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
)
```

## Experiment for Reading a Single Image
```python
from timeit import timeit
read_single_timings = dict()
for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs[method](0)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

## Reading Many Images
### Adjusting the Code for Many Images

```python
def read_many_disk(num_images):
    """ Reads image from disk.
        Parameters:
        ---------------
        num_images   number of images to read
        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    # Loop over all IDs and read each image in one by one
    for image_id in range(num_images):
        images.append(np.array(Image.open(disk_dir / f"{image_id}.png")))
    with open(disk_dir / f"{num_images}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for row in reader:
            labels.append(int(row[0]))
    return images, labels
def read_many_lmdb(num_images):
    """ Reads image from LMDB.
        Parameters:
        ---------------
        num_images   number of images to read
        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), readonly=True)
    # Start a new read transaction
    with env.begin() as txn:
        # Read all images in one single transaction, with one lock
        # We could split this up into multiple transactions if needed
        for image_id in range(num_images):
            data = txn.get(f"{image_id:08}".encode("ascii"))
            # Remember that it's a CIFAR_Image object
            # that is stored as the value
            cifar_image = pickle.loads(data)
            # Retrieve the relevant bits
            images.append(cifar_image.get_image())
            labels.append(cifar_image.label)
    env.close()
    return images, labels
def read_many_hdf5(num_images):
    """ Reads image from HDF5.
        Parameters:
        ---------------
        num_images   number of images to read
        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "r+")
    images = np.array(file["/images"]).astype("uint8")
    labels = np.array(file["/meta"]).astype("uint8")
    return images, labels
_read_many_funcs = dict(
    disk=read_many_disk, lmdb=read_many_lmdb, hdf5=read_many_hdf5
)
```
Fungsi read_many_disk sepertinya bertanggung jawab untuk membaca sejumlah gambar beserta labelnya dari disk dan mengembalikan array 
gambar dan label tersebut. Fungsi ini mungkin digunakan ketika kita ingin membaca beberapa gambar dari penyimpanan disk sekaligus, 
misalnya dari sebuah direktori yang berisi kumpulan gambar dengan file-file label terkait.

### perbandingan ketiga metode

1. Penyimpanan langsung ke dalam file-file di disk adalah cara yang sederhana, tapi kurang efisien untuk proyek yang besar dan kompleks

2. Metode menggunakan LMDB memberikan kinerja yang bagus dan bisa menghemat ruang, tapi butuh pemahaman teknis yang lebih dalam dan setelan awal yang tepat.

3. Metode menggunakan HDF5 memberikan keseimbangan antara kinerja dan kemudahan penggunaan, cocok untuk proyek dengan kompleksitas menengah hingga besar.

## KESIMPULAN
Dalam konteks analisis terabyte gambar medis, pemilihan metode penyimpanan harus mempertimbangkan trade-off antara kinerja, efisiensi penyimpanan, 
dan kompleksitas implementasi. Perlu diingat bahwa implementasi sebenarnya mungkin akan lebih kompleks tergantung pada struktur penyimpanan data yang digunakan 
di disk dan format file  gambar dan label. Misalnya, jika gambar dan label disimpan dalam file yang berbeda atau dalam format yang berbeda, perlu dilakukan penanganan 
khusus untuk membaca dan memprosesnya dengan benar.



## GitHub Documents

This is an R Markdown format used for publishing markdown documents to GitHub. When you click the **Knit** button all R code chunks are run and a markdown file (.md) suitable for publishing to GitHub is generated.
